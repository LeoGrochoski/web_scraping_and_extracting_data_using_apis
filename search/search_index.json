{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Extra\u00e7\u00e3o de Dados da Web","text":"<p>Web scraping \u00e9 usado para extra\u00e7\u00e3o de dados relevantes de p\u00e1ginas da web. Se voc\u00ea precisar de alguns dados de uma p\u00e1gina da web de dom\u00ednio p\u00fablico, o web scraping torna o processo de extra\u00e7\u00e3o de dados bastante conveniente. </p> <p>O uso de web scraping, entretanto, requer algum conhecimento b\u00e1sico da estrutura das p\u00e1ginas HTML. Neste projeto, demonstrarei o processo de an\u00e1lise do c\u00f3digo HTML de uma p\u00e1gina da web e como extrair as informa\u00e7\u00f5es necess\u00e1rias dela usando web scraping em Python.</p>"},{"location":"#dados","title":"Dados","text":"Filme Ano Avalia\u00e7\u00e3o Rotten Tomatoes The Godfather 1972 17 Citizen Kane 1941 2 Casablanca 1942 8 \"The Godfather, Part II\" 1974 99 Singin' in the Rain 1952 52 Psycho 1960 88 Rear Window 1954 47 Apocalypse Now 1979 unranked 2001: A Space Odyssey 1968 unranked Seven Samurai 1954 49 Vertigo 1958 unranked unset Blvd 1950 21 Modern Times 1936 4 Lawrence of Arabia 1962 unranked North by Northwest 1959 79 Star Wars 1977 unranked Parasite 2019 6 Schindler's List 1993 unranked Lord of the Rings: The Fellowship of the Ring 2001 unranked Shawshank Redemption 1994 unranked It's a Wonderful Life 1946 unranked Pulp Fiction 1994 unranked Avengers: Endgame 2019 7 City Lights 1931 unranked One Flew Over the Cuckoo's Nest 1975 unranked"},{"location":"#funcoes","title":"Fun\u00e7\u00f5es","text":"<p>load_webpage() </p> <p>Fun\u00e7\u00e3o para carregar a pagina da web desejada para realizar o web scrapping</p> <ol> <li> <p>Utiliza a biblioteca requests passando a url como parametro</p> </li> <li> <p>Utiliza a biblioteca BeautifulSoup para retornar o html parseado da pagina.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>url do site que iremos realizar o web scrapping.</p> required <p>Returns:</p> Name Type Description <code>data</code> <code>str</code> <p>Retorna o html da pagina parseado.</p> Source code in <code>src\\webscrapping_movies.py</code> <pre><code>def load_webpage(url: str) -&gt; str:\n    \"\"\"\n    Fun\u00e7\u00e3o para carregar a pagina da web desejada para realizar o web scrapping\n\n    1. Utiliza a biblioteca requests passando a url como parametro\n\n    2. Utiliza a biblioteca BeautifulSoup para retornar o html parseado da pagina.\n\n    Args:\n        url (str): url do site que iremos realizar o web scrapping.\n\n    Returns:\n        data (str): Retorna o html da pagina parseado.\n    \"\"\"\n    site: str = requests.get(url).text\n    data: str = BeautifulSoup(site, 'html.parser')\n    return data\n</code></pre> <p>find_tables() </p> <p>Fun\u00e7\u00e3o para receber o HTML iterar sobre os dados e retornar um dataframe das colunas e linhas desejadas</p> <ol> <li> <p>Itera sobre o conteudo da variavei rows(linhas).</p> </li> <li> <p>Checa pelo contador do loop for para restringir a 25 entradas.</p> </li> <li> <p>Extrai todos os objetos 'td' na linha e salva na variavel col.</p> </li> <li> <p>Checa se o tamanho da variavel col \u00e9 0. se n\u00e3o houver dados na linha atual. O passo \u00e9 importante desde que muitas vezes que a linhas que n\u00e3o s\u00e3o aparentes na internet. </p> </li> <li> <p>Cria um dicionario com a variavel data_dict com as chaves mesmo que as colunas do DataFrame foram criadas para gravar a saida e os valores das 3 colunas.</p> </li> <li> <p>Converte o dicionario em um dataframe e concatena em um dicionario existente. Dessa forma os dados s\u00e3o incluidos continuamente cada vez que ha uma itera\u00e7\u00e3o no loop.</p> </li> <li> <p>Incrementa o contador do loop.</p> </li> <li> <p>Uma vez que o contado atinge a marca de 50, a itera\u00e7\u00e3o \u00e9 interrompida sobre as linhas e o loop \u00e9 quebrado.    </p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>HTML da pagina web.</p> required <p>Returns:</p> Name Type Description <code>df</code> <code>str</code> <p>Retorna um dataframe contendo os 25 primeiros filmes com seu nome, ano de lan\u00e7amento e posi\u00e7\u00e3o no Rotten Tomatoes.</p> Source code in <code>src\\webscrapping_movies.py</code> <pre><code>def find_tables(data: str) -&gt; str:\n    \"\"\"\n    Fun\u00e7\u00e3o para receber o HTML iterar sobre os dados e retornar um dataframe das colunas e linhas desejadas\n\n    1. Itera sobre o conteudo da variavei rows(linhas).\n\n    2. Checa pelo contador do loop for para restringir a 25 entradas.\n\n    3. Extrai todos os objetos 'td' na linha e salva na variavel col.\n\n    4. Checa se o tamanho da variavel col \u00e9 0. se n\u00e3o houver dados na linha atual. O passo \u00e9 importante desde que muitas vezes que a linhas que n\u00e3o s\u00e3o aparentes na internet. \n\n    5. Cria um dicionario com a variavel data_dict com as chaves mesmo que as colunas do DataFrame foram criadas para gravar a saida e os valores das 3 colunas.\n\n    6. Converte o dicionario em um dataframe e concatena em um dicionario existente. Dessa forma os dados s\u00e3o incluidos continuamente cada vez que ha uma itera\u00e7\u00e3o no loop.\n\n    7. Incrementa o contador do loop.\n\n    8. Uma vez que o contado atinge a marca de 50, a itera\u00e7\u00e3o \u00e9 interrompida sobre as linhas e o loop \u00e9 quebrado.    \n\n    Args:\n        data (str): HTML da pagina web.\n\n    Returns:\n        df (str): Retorna um dataframe contendo os 25 primeiros filmes com seu nome, ano de lan\u00e7amento e posi\u00e7\u00e3o no Rotten Tomatoes.\n    \"\"\"\n    df: DataFrame = pd.DataFrame(columns=[\"Filme\",\"Ano\", \"Avalia\u00e7\u00e3o Rotten Tomatoes\"])\n    count: int = 0\n    tables = data.find_all('tbody')\n    rows = tables[0].find_all('tr')\n    for row in rows:\n        if count&lt;25:\n            col = row.find_all('td')\n            if len(col)!=0:\n                data_dict: dict = {\"Filme\": col[1].contents[0],\n                            \"Ano\": col[2].contents[0],\n                            \"Avalia\u00e7\u00e3o Rotten Tomatoes\": col[3].contents[0]}\n                df1: DataFrame = pd.DataFrame(data_dict, index=[0])\n                df: DataFrame = pd.concat([df,df1], ignore_index=True)\n                count+=1\n        else:\n            break\n    return df \n</code></pre> <p>transform_data() </p> <p>Fun\u00e7\u00e3o para transforma\u00e7\u00e3o dos dados de DataFrame para CSV</p> <p>Args: \u00c9 passado o dataframe gerado anteriormente</p> <p>Returns: Retorna um arquivo .csv salvo no diretorio data.</p> Source code in <code>src\\webscrapping_movies.py</code> <pre><code>def transform_data(df: DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Fun\u00e7\u00e3o para transforma\u00e7\u00e3o dos dados de DataFrame para CSV\n\n    Args: \u00c9 passado o dataframe gerado anteriormente\n\n    Returns: Retorna um arquivo .csv salvo no diretorio data. \n    \"\"\"\n    df.to_csv(csv_path)\n</code></pre> <p>save_db() </p> <p>Fun\u00e7\u00e3o para salvar o DataFrame em um banco de dados SQLite no caminho especificado.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame contendo os dados a serem salvos.</p> required <code>db_path</code> <code>str</code> <p>Caminho completo onde o banco de dados ser\u00e1 salvo.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\webscrapping_movies.py</code> <pre><code>def save_db(df: DataFrame, db_dir: str) -&gt; None:\n    \"\"\"\n    Fun\u00e7\u00e3o para salvar o DataFrame em um banco de dados SQLite no caminho especificado.\n\n    Args:\n        df (pd.DataFrame): DataFrame contendo os dados a serem salvos.\n        db_path (str): Caminho completo onde o banco de dados ser\u00e1 salvo.\n\n    Returns:\n        None\n    \"\"\"\n    os.makedirs(os.path.dirname(db_dir), exist_ok=True)\n    conn = sqlite3.connect(db_dir)\n    df.to_sql(table_name, conn, if_exists='replace', index=False)\n    conn.close()\n</code></pre>"},{"location":"assets/consulta_banco/","title":"Consulta dos Dados ap\u00f3s serem inseridos no Banco de Dados","text":"<p>SQLite3 \u00e9 uma biblioteca Python em processo que implementa um mecanismo de banco de dados SQL transacional independente, sem servidor e sem configura\u00e7\u00e3o. \u00c9 uma escolha popular como banco de dados incorporado para armazenamento local/cliente em software aplicativo.</p>"},{"location":"assets/consulta_banco/#funcoes","title":"Fun\u00e7\u00f5es","text":"<p>select_table() </p> <p>Fun\u00e7\u00e3o para rodar a query de busca da tabela no banco sqlite e nos retorna um Dataframe</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>Trata-se do path do banco</p> required <code>query</code> <code>str</code> <p>Trata-se da query de consulta utilizada como parametro, no caso utilizamos um select simples</p> required Source code in <code>sql\\query1.py</code> <pre><code>def select_table(db, query):\n    \"\"\"\n    Fun\u00e7\u00e3o para rodar a query de busca da tabela no banco sqlite e nos retorna um Dataframe\n\n    Args: \n        db (str): Trata-se do path do banco\n        query (str): Trata-se da query de consulta utilizada como parametro, no caso utilizamos um select simples\n    \"\"\"\n    sql_connection = sqlite3.connect(db)\n    df = pd.read_sql(query, sql_connection)\n    return df\n</code></pre>"}]}